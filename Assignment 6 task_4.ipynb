{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4b3ed2-68b7-4b44-8972-6df2ac5b00fc",
   "metadata": {},
   "source": [
    "**Assignment 6**\n",
    "\n",
    "**Image and Video Analytics**\n",
    "\n",
    "**Vishali Sharma**\n",
    "\n",
    "**21MIA1066**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e83b5-0e74-40a2-904b-7122165a51bc",
   "metadata": {},
   "source": [
    "**Task 4: Number of People Entering and Exiting the Shop**\n",
    "    \n",
    "**Objective:**\n",
    "    \n",
    "**Count the number of people entering and exiting a shop based on video footage, using basic motion detection techniques.**\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "**Load Video:**\n",
    "\n",
    "**Load the provided surveillance video of the shop entrance.**\n",
    "\n",
    "**Motion Detection:**\n",
    "\n",
    "Use frame differencing or optical flow to detect motion as people enter and exit the shop.*\n",
    "Define a region of interest (ROI) near the entrance to focus on counting people.\n",
    "Counting People:\n",
    "\n",
    "Track the direction of motion (inward or outward) based on detected motion in the ROI.\n",
    "Increment a counter for each person entering and exiting.\n",
    "Result:\n",
    "\n",
    "Display the total number of people who entered and exited the shop during the recorded period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fec3bde-2cd5-4fe6-a654-17306098f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8579de-07c5-4b87-ba40-51d44a3ffd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final count - Entered: 1, Exited: 2\n"
     ]
    }
   ],
   "source": [
    "#task-4:\n",
    "# Load the video\n",
    "video_path = r\"shoppinginndout.mp4\"  # Replace with your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Define region of interest (ROI) near the entrance\n",
    "roi_x, roi_y, roi_width, roi_height = 445, 200, 200, 150  # Adjust based on entrance position\n",
    "\n",
    "# Background subtraction for motion detection\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50)\n",
    "\n",
    "# Initialize counters for people entering and exiting\n",
    "enter_count = 0\n",
    "exit_count = 0\n",
    "\n",
    "# Variables to hold movement direction\n",
    "last_direction = None\n",
    "direction_threshold = 30  # Minimum movement threshold for counting\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Define the ROI for detecting motion at the entrance\n",
    "    roi = frame[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)\n",
    "\n",
    "    # Detect motion using background subtraction\n",
    "    fg_mask = fgbg.apply(blurred_roi)\n",
    "    _, fg_mask = cv2.threshold(fg_mask, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours to identify moving objects\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        # Ignore small contours to avoid noise\n",
    "        if cv2.contourArea(contour) < 500:\n",
    "            continue\n",
    "\n",
    "        # Draw bounding box around detected motion in the ROI\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(roi, (x, y), (x+w, y+h), (100, 255, 100), 2)\n",
    "\n",
    "        # Calculate movement direction (up for entering, down for exiting)\n",
    "        if last_direction is None:\n",
    "            last_direction = y\n",
    "        else:\n",
    "            direction = y - last_direction\n",
    "            if abs(direction) > direction_threshold:\n",
    "                if direction < 0:\n",
    "                    enter_count += 1\n",
    "                    #print(f\"Person entered, Total Entered: {enter_count}\")\n",
    "                elif direction > 0:\n",
    "                    exit_count += 1\n",
    "                    #print(f\"Person exited, Total Exited: {exit_count}\")\n",
    "                last_direction = y\n",
    "\n",
    "    # Display the frame with ROI and motion highlighted\n",
    "    cv2.rectangle(frame, (roi_x, roi_y), (roi_x+roi_width, roi_y+roi_height), (255, 0, 0), 2)\n",
    "    cv2.putText(frame, f\"Entered: {enter_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Exited: {exit_count}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Shop Entrance\", frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Final count - Entered: {enter_count}, Exited: {exit_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169b761-c258-4d45-b333-8f8603d43468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
