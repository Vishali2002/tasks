{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab63d49-1675-404c-8baf-dda3324c62e4",
   "metadata": {},
   "source": [
    "**Assignment 6**\n",
    "\n",
    "**Image and Video Analytics**\n",
    "\n",
    "**Vishali Sharma**\n",
    "\n",
    "**21MIA1066**\n",
    "\n",
    "Task 3: Facial Recognition to Check Fraud Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0546266b-8fb9-4eb6-8312-f69a6b5fca3a",
   "metadata": {},
   "source": [
    "Objective:\n",
    "Identify a suspect by comparing their facial features to a reference image to check for fraud cases, using traditional facial recognition techniques.\n",
    "\n",
    "Task Description:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90230c73-96dc-4c45-b3f6-de532caaeeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee3f29c-617c-4b13-b5fa-72f214657d39",
   "metadata": {},
   "source": [
    "**Load the reference image of the suspect and a video showing multiple faces.**\n",
    "\n",
    "**Face Detection:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9122e6-b268-48ee-aa61-449538b6e050",
   "metadata": {},
   "source": [
    "**Use Haar Cascades to detect faces in both the reference image and the video.**\n",
    "\n",
    "**Feature Matching:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377c7ec-6ccb-4d99-b91f-381511d5c350",
   "metadata": {},
   "source": [
    "**Extract facial features using edge detection or geometric facial features (eye spacing, nose length, etc.).**\n",
    "\n",
    "**Compare the features of the faces in the video with the reference face to check for a match.**\n",
    "                                                                                 \n",
    "**Result:**\n",
    "\n",
    "**Output the frames where a match is found and highlight the detected face in the video.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea6b2a7-286f-4772-9066-c3953c0ca2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 face(s) detected in the reference image.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Set paths for reference image and video\n",
    "reference_image_path = \"suspectimg.jpg\"\n",
    "video_path = \"suspect.mp4\"\n",
    "\n",
    "# Specify output folder for matched frames\n",
    "output_folder = \"suspect_frame\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load the reference image and convert it to grayscale\n",
    "reference_image = cv2.imread(reference_image_path)\n",
    "reference_gray = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Load Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Detect face in the reference image\n",
    "ref_faces = face_cascade.detectMultiScale(reference_gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Ensure there's at least one face detected in the reference image\n",
    "if len(ref_faces) == 0:\n",
    "    print(\"No faces found in the reference image.\")\n",
    "else:\n",
    "    print(f\"{len(ref_faces)} face(s) detected in the reference image.\")\n",
    "\n",
    "    # Extract the detected face from the reference image (use the largest face)\n",
    "    x, y, w, h = max(ref_faces, key=lambda face: face[2] * face[3])\n",
    "    reference_face = reference_gray[y:y+h, x:x+w]\n",
    "\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    # Process each frame in the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        match_found = False  # Flag to check if any match is found in the current frame\n",
    "\n",
    "        # Process each detected face in the frame\n",
    "        for (fx, fy, fw, fh) in faces:\n",
    "            face_in_frame = gray_frame[fy:fy+fh, fx:fx+fw]\n",
    "            resized_reference = cv2.resize(reference_face, (fw, fh))\n",
    "            match_result = cv2.matchTemplate(face_in_frame, resized_reference, cv2.TM_CCOEFF_NORMED)\n",
    "            _, match_val, _, _ = cv2.minMaxLoc(match_result)\n",
    "\n",
    "            match_threshold = 0.7\n",
    "            if match_val > match_threshold:\n",
    "                # Draw a rectangle and label on the matching face\n",
    "                cv2.rectangle(frame, (fx, fy), (fx + fw, fy + fh), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'Match: {match_val:.2f}', (fx, fy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                print(f\"Match found in frame {frame_count} with similarity score: {match_val:.2f}\")\n",
    "\n",
    "                # Save the frame with the match to the output folder\n",
    "                output_frame_path = os.path.join(output_folder, f'frame_{frame_count}.jpg')\n",
    "                cv2.imwrite(output_frame_path, frame)\n",
    "                match_found = True\n",
    "\n",
    "        # Display matched frames in Jupyter Notebook\n",
    "        if match_found:\n",
    "            display(Image(filename=output_frame_path))\n",
    "\n",
    "    # Release video capture\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e5d19b-e89e-46a7-b5c7-eee7cd09c873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 651\n"
     ]
    }
   ],
   "source": [
    "# Load the reference image of the suspect\n",
    "suspect_image = cv2.imread('suspectimg.jpg')  # Provide your reference image file path\n",
    "\n",
    "# Load the video file\n",
    "cap = cv2.VideoCapture('suspect.mp4')  # Provide your video file path\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    # Get the total number of frames\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "\n",
    "# Release the video capture object when done\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64c6618-d999-4bc7-86a0-702bdf4a36c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca8e050b69b422fa24f14649587ee6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load and process the suspect image\n",
    "suspect_image = cv2.imread('suspectimg.jpg')\n",
    "gray_suspect = cv2.cvtColor(suspect_image, cv2.COLOR_BGR2GRAY)\n",
    "suspect_faces = face_cascade.detectMultiScale(gray_suspect, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Check for faces in the suspect image\n",
    "if len(suspect_faces) == 0:\n",
    "    print(\"No face detected in the reference image.\")\n",
    "else:\n",
    "    # Crop the first detected face in the suspect image\n",
    "    x, y, w, h = suspect_faces[0]\n",
    "    suspect_face = gray_suspect[y:y+h, x:x+w]\n",
    "\n",
    "    # Use ORB (Oriented FAST and Rotated BRIEF) for feature detection and description\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(suspect_face, None)\n",
    "\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture('suspect.mp4')\n",
    "    output_widget = widgets.Output()\n",
    "    display(output_widget)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        # Convert frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the video frame\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            # Crop and analyze each detected face in the frame\n",
    "            frame_face = gray_frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Detect features in the face from the current frame\n",
    "            keypoints2, descriptors2 = orb.detectAndCompute(frame_face, None)\n",
    "\n",
    "            # Ensure both faces have descriptors for matching\n",
    "            if descriptors1 is not None and descriptors2 is not None:\n",
    "                # Use BFMatcher with Hamming distance\n",
    "                bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "                matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "                # Filter good matches based on distance\n",
    "                good_matches = [m for m in matches if m.distance < 30]\n",
    "\n",
    "                # Check if the number of good matches exceeds a threshold\n",
    "                if len(good_matches) > 15:\n",
    "                    # Draw rectangle and label the suspect face\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, \"Suspect Person\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the processed frame in the Jupyter Notebook\n",
    "        with output_widget:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img_pil = Image.fromarray(frame_rgb)\n",
    "            clear_output(wait=True)\n",
    "            display(img_pil)\n",
    "\n",
    "        # Optionally display the frame in a separate window\n",
    "        cv2.imshow(\"Video Frame - Suspect Detection\", frame)\n",
    "\n",
    "        # Press 'q' to exit early\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release video and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52ffaddc-df3d-411f-ab08-93e4fe1c72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Convert the reference image to grayscale\n",
    "gray_suspect = cv2.cvtColor(suspect_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the reference image\n",
    "suspect_faces = face_cascade.detectMultiScale(gray_suspect, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Check if any faces were detected in the reference image\n",
    "if len(suspect_faces) == 0:\n",
    "    print(\"No face detected in the reference image.\")\n",
    "else:\n",
    "    # Crop and display each detected face in the reference image\n",
    "    for (x, y, w, h) in suspect_faces:\n",
    "        suspect_face = gray_suspect[y:y+h, x:x+w]\n",
    "        cv2.imshow(\"Suspect Face\", suspect_face)\n",
    "        cv2.waitKey(0)  # Press any key to close the suspect face window\n",
    "\n",
    "# Now process each frame in the video to detect faces\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Exit the loop if no frame is read (end of video)\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the current video frame\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Draw rectangles around detected faces in the frame\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame with detected faces\n",
    "    cv2.imshow(\"Video Frame - Face Detection\", frame)\n",
    "\n",
    "    # Press 'q' to quit early\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8aafa-4e90-45c1-b977-24af17a78354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
